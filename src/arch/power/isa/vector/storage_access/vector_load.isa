format VecLoadIndexOp {
    7: lvebx({{
        Vt_uq[0] = Mem_uq;
    }});

    39: lvehx({{
        Vt_uq[0] = Mem_uq;
    }});

    71: lvewx({{
        Vt_uq[0] = Mem_uq;
    }});

    103: lvx({{
        Vt_uq[0] = Mem_uq;
    }});

    359: lvxl({{
        Vt_uq[0] = Mem_uq;
    }});

    6: lvsl({{
        uint8_t sh = bits(EA, 3, 0);
        __uint128_t val_128;
        uint8_t *val = (uint8_t *)&val_128;
        Mem_uq;

        uint8_t bytes[] = {
            0x1f, 0x1e, 0x1d, 0x1c, 0x1b, 0x1a, 0x19, 0x18, 
            0x17, 0x16, 0x15, 0x14, 0x13, 0x12, 0x11, 0x10,
            0x0f, 0x0e, 0x0d, 0x0c, 0x0b, 0x0a, 0x09, 0x08, 
            0x07, 0x06, 0x05, 0x04, 0x03, 0x02, 0x01, 0x00
        };

        for(auto i = 0; i < 16; i++) {
            val[i] = bytes[16 + (i - sh)];
        }
        Vt_uq[0] = val_128;
    }});

    38: lvsr({{
        uint8_t sh = bits(EA, 3, 0);
        __uint128_t val_128;
        uint8_t *val = (uint8_t *)&val_128;
        Mem_uq;

        uint8_t bytes[] = {
            0x1f, 0x1e, 0x1d, 0x1c, 0x1b, 0x1a, 0x19, 0x18, 
            0x17, 0x16, 0x15, 0x14, 0x13, 0x12, 0x11, 0x10,
            0x0f, 0x0e, 0x0d, 0x0c, 0x0b, 0x0a, 0x09, 0x08, 
            0x07, 0x06, 0x05, 0x04, 0x03, 0x02, 0x01, 0x00
        };

        for(auto i = 0; i < 16; i++)
            val[i] = bytes[(i + sh)];
        Vt_uq[0] = val_128;
    }});
}